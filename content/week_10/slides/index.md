---
date: 2023-12-19
execute:
  echo: true
  fig-dpi: 600
includes:
  css: ./assets/css/style.css
title: Validity, reliability, assignment
toc-title: Table of contents
type: revealjs
---

## Today

::: incremental
-   What makes a good measure?
    -   Validity
    -   Reliability
-   January assignment
:::

## Validity and reliability

-   All measurement involves the use of a tool (or *measure*)

    -   Tape measure

    -   Stopwatch

    -   Questionnaire

    -   Exam

    -   Experimental task

-   Tools must be **valid** and **reliable**.

## Validity

::: incremental
-   A measurement tool is **valid** if it measures that which *it is
    supposed to measure*

-   We can talk about several kinds of Validity

    -   Construct validity
    -   Convergent & discriminant validity
    -   Ecological validity
    -   Face validity
:::

## Construct validity

::: incremental
-   We often deal with concepts or *constructs* that **cannot be
    observed directly**

    -   Walkability, centrality, attitudes, satisfaction...

-   There are tools, such as questionnaires, metrics, indices, and
    experimental tasks to gather information about these unobservable
    things

-   **Construct validity** is the extent to which a tool can be
    justifiably trusted to actually measure the construct it is supposed
    to measure.

-   All tools are **informed by the theoretical underpinnings** behind
    the constructs that they are designed to measure

    -   *There is no such thing as an atheoretical measurement
        instrument*
:::

## Convergent & discriminant Validity

::: incremental
-   Ways of assessing construct validity

-   **Convergent** validity is the extent to which the measure is
    related to other measures with which it **should** be related

    -   Various measures of centrality should be related

-   **Discriminant** validity is the extent to which the measure **not
    related** related to other measures with which it **should not** be
    related

    -   Space syntax is *not* supposed to be just a traffic model
:::

## External validity

::: incremental
-   **feature of study design**, not measurement tool

-   A study has external validity if its findings can be applied to the
    entire population of people/things/instances *with relevant
    characteristics* and if they hold up in real-world conditions

    -   If study uses a sample of mid-sized German cities, the findings
        may be true for *mid-sized German cities **in general***

    -   They may not apply - **generalise** - to all cities
:::

## External validity

::: incremental
-   The amount to which findings apply in the real world outside of the
    study is **ecological validity**

    -   Experiments and simulations can have low ecological validity

    -   Just because something is true in the lab or simulation doesn't
        mean it is going to be true in the real world

-   Analogous to **transferability** in qualitative research
:::

## Reliability

::: incremental
-   An instrument is reliable if it produces **accurate and stable**
    results under consistent conditions

-   Reliable tests have low measurement error and bias

-   We can distinguish between

    -   Test-retest reliability
    -   Inter-rater Reliability
    -   Internal consistency
:::

## Test-retest reliability

::: incremental
-   A score on a stats exam should be an *accurate* reflection of a
    person's stats ability and not something else

    -   Shouldn't be assessing other things, like anxiety, IT skills,
        *etc.*

    -   If two people take the test, the one with the better stats
        skills should have a higher score

-   Score on test taken at two time points should give same results if
    nothing was learned or forgotten in the meantime

    -   This stability over time is **test-retest** reliability.

-   Example: Space brightness
:::

## Inter-rater reliability

::: incremental
-   Often measurement and observation require rating/labelling
    -   Land use, activity type, footfall
    -   Data for supervised machine learning models
    -   Heavily used in qualitative research
-   Good practice to involve multiple raters rating the same
    data/situations
-   Inter-rater reliability expresses the level of **agreement** between
    raters
:::

## Internal consistency

::: incremental
-   Applies to questionnaires
-   The extent to which the individual items relate to one another
-   There are mathematical/psychometric tool to assess it
:::

## Validity vs Reliability

![](./assets/val_rel.png){data-source="https://qhaireenizzati.wordpress.com/2017/11/26/validity-and-reliability/"
height="500px"}

## Questions?

## January assignment

**Revised deadline**: 8 January (opens 5 Jan, closes 8 Jan at 23:59:59
CET)

-   Introduction section to your research project

-   Submission via Moodle course page

-   Worth 40% of the final grade

## Format

-   Electronic only - `.doc(x)`, `.odt`, HTML, PDF
-   Maximum 1,200 words
-   Written in English
-   Be conservative with graphics
-   11-12pt text (Calibri, Times New Roman, or similar)
    -   Please no Papyrus, Comic Sans or similar fun/novelty fonts
-   Double line spacing, standard page margins, page numbers
-   Consistent citation and referencing style (APA, preferably)

## Structure

-   Clearly stated research problem
-   Review of current state of knowledge (AKA "State of the art")
-   A clear line of argument connecting research problem with research
    question/hypothesis, supported by evidence from reviewed literature
    (with proper citations)
-   If appropriate, sections with headings may be included
-   Explicitly stated research question/hypothesis
-   List of references, consistently formatted according to used style
    guide

## Assessment criteria

-   Clarity, relevance, and feasibility of research question/hypothesis
-   Engagement with literature
-   Coherence and validity of argumentation
-   Clarity and conciseness of written expression
-   Consistency citation and referencing style
-   Adherence to formal requirements
